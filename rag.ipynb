{
 "cells": [
  {
   "cell_type": "code",
   "id": "572fbdd007709a38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T16:18:31.275221Z",
     "start_time": "2024-06-19T16:18:23.203355Z"
    }
   },
   "source": [
    "from src.ingestion import Ingestion\n",
    "import glob\n",
    "\n",
    "ingestion = Ingestion()\n",
    "\n",
    "# for file in glob.glob(\"data/v1/docs/*.pdf\"):\n",
    "#     ingestion.ingest_pdf(\n",
    "#         file=file\n",
    "#     )\n",
    "\n",
    "ingestion.ingest_document(\"extracted_data.json\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ausar/miniconda3/envs/rag_agent/lib/python3.10/site-packages/chroma/util/check_latest_version.py:32: UserWarning: A newer version of chroma (3.9.10) is available. It's recommended that you update to the latest version using `pip install -U chroma`.\n",
      "  warnings.warn(\n",
      "/home/ausar/miniconda3/envs/rag_agent/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "Creating 100 embeddings in 1 batches of size 100::   0%|          | 0/1 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "GoogleGenerativeAIError",
     "evalue": "Error embedding content: 404 models/text-multilingual-embedding-002 is not found for API version v1beta, or is not supported for batchEmbedContents. Call ListModels to see the list of available models and their supported methods.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFound\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/langchain_google_genai/embeddings.py:146\u001B[0m, in \u001B[0;36mGoogleGenerativeAIEmbeddings.embed_documents\u001B[0;34m(self, texts, task_type, titles, output_dimensionality)\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 146\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_embed_contents\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[43m        \u001B[49m\u001B[43mBatchEmbedContentsRequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequests\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequests\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    148\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:1350\u001B[0m, in \u001B[0;36mGenerativeServiceClient.batch_embed_contents\u001B[0;34m(self, request, model, requests, retry, timeout, metadata)\u001B[0m\n\u001B[1;32m   1349\u001B[0m \u001B[38;5;66;03m# Send the request.\u001B[39;00m\n\u001B[0;32m-> 1350\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mrpc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1352\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1354\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1357\u001B[0m \u001B[38;5;66;03m# Done; return the response.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001B[0m, in \u001B[0;36m_GapicCallable.__call__\u001B[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001B[0m\n\u001B[1;32m    129\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m compression\n\u001B[0;32m--> 131\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001B[0m, in \u001B[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    290\u001B[0m sleep_generator \u001B[38;5;241m=\u001B[39m exponential_sleep_generator(\n\u001B[1;32m    291\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initial, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maximum, multiplier\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_multiplier\n\u001B[1;32m    292\u001B[0m )\n\u001B[0;32m--> 293\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mretry_target\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    294\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predicate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    296\u001B[0m \u001B[43m    \u001B[49m\u001B[43msleep_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    298\u001B[0m \u001B[43m    \u001B[49m\u001B[43mon_error\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mon_error\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    299\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001B[0m, in \u001B[0;36mretry_target\u001B[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;66;03m# defer to shared logic for handling errors\u001B[39;00m\n\u001B[0;32m--> 153\u001B[0m     \u001B[43m_retry_error_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdeadline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43msleep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpredicate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mon_error\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexception_factory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;66;03m# if exception not raised, sleep before next attempt\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001B[0m, in \u001B[0;36m_retry_error_helper\u001B[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001B[0m\n\u001B[1;32m    207\u001B[0m     final_exc, source_exc \u001B[38;5;241m=\u001B[39m exc_factory_fn(\n\u001B[1;32m    208\u001B[0m         error_list,\n\u001B[1;32m    209\u001B[0m         RetryFailureReason\u001B[38;5;241m.\u001B[39mNON_RETRYABLE_ERROR,\n\u001B[1;32m    210\u001B[0m         original_timeout,\n\u001B[1;32m    211\u001B[0m     )\n\u001B[0;32m--> 212\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m final_exc \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msource_exc\u001B[39;00m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m on_error_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001B[0m, in \u001B[0;36mretry_target\u001B[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 144\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mtarget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39misawaitable(result):\n",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/google/api_core/timeout.py:120\u001B[0m, in \u001B[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    118\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout \u001B[38;5;241m-\u001B[39m time_since_first_attempt)\n\u001B[0;32m--> 120\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001B[0m, in \u001B[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m grpc\u001B[38;5;241m.\u001B[39mRpcError \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m---> 78\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mfrom_grpc_error(exc) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mexc\u001B[39;00m\n",
      "\u001B[0;31mNotFound\u001B[0m: 404 models/text-multilingual-embedding-002 is not found for API version v1beta, or is not supported for batchEmbedContents. Call ListModels to see the list of available models and their supported methods.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mGoogleGenerativeAIError\u001B[0m                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 11\u001B[0m\n\u001B[1;32m      4\u001B[0m ingestion \u001B[38;5;241m=\u001B[39m Ingestion()\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# for file in glob.glob(\"data/v1/docs/*.pdf\"):\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m#     ingestion.ingest_pdf(\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m#         file=file\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m#     )\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m \u001B[43mingestion\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mingest_document\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mextracted_data.json\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/rag_agent/src/ingestion.py:49\u001B[0m, in \u001B[0;36mIngestion.ingest_document\u001B[0;34m(self, document)\u001B[0m\n\u001B[1;32m     47\u001B[0m vs \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m chunk_generator(chunks):\n\u001B[0;32m---> 49\u001B[0m     _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext_vectorstore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/langchain_core/vectorstores.py:138\u001B[0m, in \u001B[0;36mVectorStore.add_documents\u001B[0;34m(self, documents, **kwargs)\u001B[0m\n\u001B[1;32m    136\u001B[0m texts \u001B[38;5;241m=\u001B[39m [doc\u001B[38;5;241m.\u001B[39mpage_content \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[1;32m    137\u001B[0m metadatas \u001B[38;5;241m=\u001B[39m [doc\u001B[38;5;241m.\u001B[39mmetadata \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[0;32m--> 138\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_texts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:260\u001B[0m, in \u001B[0;36mDeepLake.add_texts\u001B[0;34m(self, texts, metadatas, ids, **kwargs)\u001B[0m\n\u001B[1;32m    257\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`texts` parameter shouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt be empty.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 260\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvectorstore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    262\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[43m        \u001B[49m\u001B[43membedding_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    264\u001B[0m \u001B[43m        \u001B[49m\u001B[43membedding_tensor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43membedding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    265\u001B[0m \u001B[43m        \u001B[49m\u001B[43membedding_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_embedding_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_documents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore\u001B[39;49;00m\n\u001B[1;32m    266\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SampleExtendError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    270\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to append a sample to the tensor \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e):\n",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/chroma/core/vectorstore/deeplake_vectorstore.py:229\u001B[0m, in \u001B[0;36mVectorStore.add\u001B[0;34m(self, embedding_function, embedding_data, embedding_tensor, return_ids, rate_limiter, **tensors)\u001B[0m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21madd\u001B[39m(\n\u001B[1;32m    151\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    152\u001B[0m     embedding_function: Optional[Union[Callable, List[Callable]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    161\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtensors,\n\u001B[1;32m    162\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[List[\u001B[38;5;28mstr\u001B[39m]]:\n\u001B[1;32m    163\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Adding elements to chroma vector store.\u001B[39;00m\n\u001B[1;32m    164\u001B[0m \n\u001B[1;32m    165\u001B[0m \u001B[38;5;124;03m    Tensor names are specified as parameters, and data for each tensor is specified as parameter values. All data must of equal length.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;124;03m        Optional[List[str]]: List of ids if ``return_ids`` is set to True. Otherwise, None.\u001B[39;00m\n\u001B[1;32m    228\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 229\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset_handler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    230\u001B[0m \u001B[43m        \u001B[49m\u001B[43membedding_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membedding_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[43m        \u001B[49m\u001B[43membedding_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membedding_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    232\u001B[0m \u001B[43m        \u001B[49m\u001B[43membedding_tensor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membedding_tensor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    233\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    234\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrate_limiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrate_limiter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/chroma/core/vectorstore/dataset_handlers/client_side_dataset_handler.py:139\u001B[0m, in \u001B[0;36mClientSideDH.add\u001B[0;34m(self, embedding_function, embedding_data, embedding_tensor, return_ids, rate_limiter, **tensors)\u001B[0m\n\u001B[1;32m    133\u001B[0m processed_tensors, id_ \u001B[38;5;241m=\u001B[39m dataset_utils\u001B[38;5;241m.\u001B[39mpreprocess_tensors(\n\u001B[1;32m    134\u001B[0m     embedding_data, embedding_tensor, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtensors\n\u001B[1;32m    135\u001B[0m )\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m id_ \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 139\u001B[0m \u001B[43mdataset_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextend_or_ingest_dataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprocessed_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprocessed_tensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membedding_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    143\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membedding_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_tensor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membedding_tensor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    145\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrate_limiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrate_limiter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    146\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlogger\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlogger\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose:\n\u001B[1;32m    150\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39msummary()\n",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/chroma/core/vectorstore/vector_search/dataset/dataset.py:535\u001B[0m, in \u001B[0;36mextend_or_ingest_dataset\u001B[0;34m(processed_tensors, dataset, embedding_function, embedding_tensor, embedding_data, rate_limiter, logger)\u001B[0m\n\u001B[1;32m    533\u001B[0m rate_limiter \u001B[38;5;241m=\u001B[39m populate_rate_limiter(rate_limiter)\n\u001B[1;32m    534\u001B[0m \u001B[38;5;66;03m# TODO: Add back the old logic with checkpointing after indexing is fixed\u001B[39;00m\n\u001B[0;32m--> 535\u001B[0m \u001B[43mextend\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    536\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    537\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    538\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_tensor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    539\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprocessed_tensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    540\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    541\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrate_limiter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    542\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlogger\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogger\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/chroma/core/vectorstore/vector_search/dataset/dataset.py:481\u001B[0m, in \u001B[0;36mextend\u001B[0;34m(embedding_function, embedding_data, embedding_tensor, processed_tensors, dataset, rate_limiter, _extend_batch_size, logger)\u001B[0m\n\u001B[1;32m    475\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m tqdm(\n\u001B[1;32m    476\u001B[0m     \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(embedding_data[\u001B[38;5;241m0\u001B[39m]), _extend_batch_size),\n\u001B[1;32m    477\u001B[0m     progressbar_str,\n\u001B[1;32m    478\u001B[0m ):\n\u001B[1;32m    479\u001B[0m     batch_start, batch_end \u001B[38;5;241m=\u001B[39m idx, idx \u001B[38;5;241m+\u001B[39m _extend_batch_size\n\u001B[0;32m--> 481\u001B[0m     batched_embeddings \u001B[38;5;241m=\u001B[39m \u001B[43m_compute_batched_embeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    482\u001B[0m \u001B[43m        \u001B[49m\u001B[43membedding_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    483\u001B[0m \u001B[43m        \u001B[49m\u001B[43membedding_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    484\u001B[0m \u001B[43m        \u001B[49m\u001B[43membedding_tensor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    485\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_start\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    486\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_end\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    487\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrate_limiter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    490\u001B[0m     batched_tensors \u001B[38;5;241m=\u001B[39m _slice_non_embedding_tensors(\n\u001B[1;32m    491\u001B[0m         processed_tensors, embedding_tensor, batch_start, batch_end\n\u001B[1;32m    492\u001B[0m     )\n\u001B[1;32m    494\u001B[0m     batched_processed_tensors \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mbatched_embeddings, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mbatched_tensors}\n",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/chroma/core/vectorstore/vector_search/dataset/dataset.py:422\u001B[0m, in \u001B[0;36m_compute_batched_embeddings\u001B[0;34m(embedding_function, embedding_data, embedding_tensor, start_idx, end_idx, rate_limiter)\u001B[0m\n\u001B[1;32m    420\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m func, data, tensor \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(embedding_function, embedding_data, embedding_tensor):\n\u001B[1;32m    421\u001B[0m     data_slice \u001B[38;5;241m=\u001B[39m data[start_idx:end_idx]\n\u001B[0;32m--> 422\u001B[0m     embedded_data \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_slice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrate_limiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrate_limiter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    424\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    425\u001B[0m         return_embedded_data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mvstack(embedded_data)\u001B[38;5;241m.\u001B[39mastype(dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat32)\n",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/chroma/core/vectorstore/embeddings/embedder.py:77\u001B[0m, in \u001B[0;36mDeepLakeEmbedder.embed_documents\u001B[0;34m(self, documents, rate_limiter)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m rate_limiter[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menabled\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m     76\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply_rate_limiter(documents, embedding_func, rate_limiter)\n\u001B[0;32m---> 77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43membedding_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/rag_agent/src/embeddings.py:16\u001B[0m, in \u001B[0;36mGeminiEmbeddings.embed_documents\u001B[0;34m(self, texts, task_type, titles, output_dimensionality)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21membed_documents\u001B[39m(\u001B[38;5;28mself\u001B[39m, texts: List[\u001B[38;5;28mstr\u001B[39m],\n\u001B[1;32m     13\u001B[0m                     task_type: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     14\u001B[0m                     titles: Optional[List[\u001B[38;5;28mstr\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     15\u001B[0m                     output_dimensionality: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[List[\u001B[38;5;28mfloat\u001B[39m]]:\n\u001B[0;32m---> 16\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtask_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtitles\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_dimensionality\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;66;03m# Convert Repeated type to list type\u001B[39;00m\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28mlist\u001B[39m, embeddings))\n",
      "File \u001B[0;32m~/miniconda3/envs/rag_agent/lib/python3.10/site-packages/langchain_google_genai/embeddings.py:150\u001B[0m, in \u001B[0;36mGoogleGenerativeAIEmbeddings.embed_documents\u001B[0;34m(self, texts, task_type, titles, output_dimensionality)\u001B[0m\n\u001B[1;32m    146\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mbatch_embed_contents(\n\u001B[1;32m    147\u001B[0m         BatchEmbedContentsRequest(requests\u001B[38;5;241m=\u001B[39mrequests, model\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel)\n\u001B[1;32m    148\u001B[0m     )\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 150\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m GoogleGenerativeAIError(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError embedding content: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [e\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m result\u001B[38;5;241m.\u001B[39membeddings]\n",
      "\u001B[0;31mGoogleGenerativeAIError\u001B[0m: Error embedding content: 404 models/text-multilingual-embedding-002 is not found for API version v1beta, or is not supported for batchEmbedContents. Call ListModels to see the list of available models and their supported methods."
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "1a09a8ec35abebb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T17:01:02.062550Z",
     "start_time": "2024-06-18T17:01:00.132698Z"
    }
   },
   "source": [
    "from src.qachain import QAChain\n",
    "\n",
    "qna = QAChain()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "50e1462e0106e82d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T17:01:02.751825Z",
     "start_time": "2024-06-18T17:01:02.747731Z"
    }
   },
   "source": [
    "# queries = [\"How has Amazon's total net sales changed over time?\", \n",
    "#          \"What are the major factors contributing to the change in Apple's gross margin in the most recent 10-Q compared to the previous quarters?\",\n",
    "#          \"Has Microsoft partaken in any substantial stock buyback programs in the reported quarters, and what are the economic consequences of these actions?\",\n",
    "#          \"What effective tax rate has Microsoft reported in these quarters and how does it differ from period to period?\",\n",
    "#          \"What are the key changes in NVIDIA's liquidity status or cash flows as disclosed in these quarterly reports?\"]\n",
    "\n",
    "queries = [\"Sinh viên được xin nghỉ học tạm thời và bảo lưu kết quả đã học trong các trường hợp nào?\"]"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "fbe953e7b9628e02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T17:01:14.048729Z",
     "start_time": "2024-06-18T17:01:05.420477Z"
    }
   },
   "source": [
    "for query in queries:\n",
    "    results = qna.ask_question(\n",
    "        query=query\n",
    "    )\n",
    "    print(\"query:\")\n",
    "    print(query)\n",
    "    print(\"answer:\")\n",
    "    print(results)\n",
    "    print('='*10)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception raised. Generating response.\n",
      "Deep Lake Dataset in database/text_vectorstore already exists, loading from the storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 1 embeddings in 1 batches of size 1:: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:\n",
      "Sinh viên được xin nghỉ học tạm thời và bảo lưu kết quả đã học trong các trường hợp nào?\n",
      "answer:\n",
      "Context hiện tại không cung cấp thông tin về việc sinh viên được xin nghỉ học tạm thời và bảo lưu kết quả đã học. \n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ebc550dcf8b018e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T03:36:03.245169Z",
     "start_time": "2024-06-03T03:36:03.242282Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
