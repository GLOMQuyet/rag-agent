{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "class Chapter(BaseModel):\n",
    "    chapter: str\n",
    "    metadatas: list\n",
    "\n",
    "class Metadata(BaseModel):\n",
    "    title: str\n",
    "    content: str\n",
    "\n",
    "def fetch_and_extract_text(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        data = []\n",
    "        chapters = soup.find_all('p', id=lambda x: x and x.startswith('Chuong'))\n",
    "\n",
    "        for index, chapter in enumerate(chapters, start=1):\n",
    "            chapter_title = chapter.find('strong').get_text(strip=True)\n",
    "            titles = [dt.get_text(strip=True) for dt in soup.find_all('dt')]\n",
    "            contents = [dd.get_text(strip=True) for dd in soup.find_all('dd')]\n",
    "            index_ranges = {\n",
    "                1: (0, 4),\n",
    "                2: (4, 20),\n",
    "                3: (20, 30),\n",
    "                4: (30, 33),\n",
    "                5: (33, 37)\n",
    "            }\n",
    "\n",
    "            start_idx, end_idx = index_ranges.get(index, (0, 0))\n",
    "            metadatas = []\n",
    "            for title, content in zip(titles[start_idx:end_idx], contents[start_idx:end_idx]):\n",
    "                metadatas.append(Metadata(title=title, content=content))\n",
    "            chapter = Chapter(chapter=chapter_title, metadatas=metadatas)\n",
    "            data.append(chapter)\n",
    "            \n",
    "        return data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching the URL: {e}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# URL of the webpage to crawl\n",
    "url = \"https://undergrad.tdtu.edu.vn/hoc-vu/quy-che-chuc-va-quan-ly-dao-tao-trinh-do-dai-hoc-khoa-ts2021-tro-ve-sau#ChuongI\"\n",
    "\n",
    "# Fetch and extract text from the URL\n",
    "extracted_data = fetch_and_extract_text(url)\n",
    "# Convert to dictionary\n",
    "extracted_data_dict = [item.dict() for item in extracted_data]\n",
    "print(extracted_data)\n",
    "# Save to JSON file\n",
    "with open('extracted_data.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(extracted_data_dict, json_file, ensure_ascii=False, indent=4)"
   ],
   "id": "8e9f0aea07bb7103"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
